{"cells":[{"cell_type":"code","execution_count":null,"id":"f7225448-88f1-42e5-8b51-ec244376e5af","metadata":{"id":"f7225448-88f1-42e5-8b51-ec244376e5af","outputId":"7b26aebc-826c-44ee-978b-4355e3f0b6a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["ls: cannot access '/home/samarth7022/my_virtualenvs': No such file or directory\n"]}],"source":["!ls ~/my_virtualenvs\n"]},{"cell_type":"code","execution_count":null,"id":"63022e71-11ac-4f03-afe4-f35247478beb","metadata":{"id":"63022e71-11ac-4f03-afe4-f35247478beb","outputId":"2ff75472-1fd2-4493-b02b-9487751d0917"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-10 15:38:38.212067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 15:38:38.360298: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-10 15:38:38.411039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-10 15:38:39.285969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 15:38:39.286050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 15:38:39.286058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"id":"310584ad-3cf4-4ea1-b02e-d9b3223e517a","metadata":{"id":"310584ad-3cf4-4ea1-b02e-d9b3223e517a","outputId":"6e03cea5-8104-4876-968c-d3ef7d07b08a"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-11 16:56:45.231413: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-11 16:56:45.387939: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-11 16:56:45.439235: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-11 16:56:46.335543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2024-11-11 16:56:46.335622: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2024-11-11 16:56:46.335631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]},{"name":"stdout","output_type":"stream","text":["GPU 1 is set for use.\n"]}],"source":["import tensorflow as tf\n","\n","# List available GPUs\n","gpus = tf.config.list_physical_devices('GPU')\n","\n","if len(gpus) > 1:\n","    # Set TensorFlow to only use GPU 1\n","    try:\n","        tf.config.set_visible_devices(gpus[1], 'GPU')\n","        # Optionally limit memory growth for GPU 1\n","        tf.config.experimental.set_memory_growth(gpus[1], True)\n","        print(\"GPU 1 is set for use.\")\n","    except RuntimeError as e:\n","        print(e)\n","else:\n","    print(\"Less than two GPUs available.\")\n"]},{"cell_type":"code","execution_count":null,"id":"e39d527d-4692-4e76-acef-9a821301ed74","metadata":{"id":"e39d527d-4692-4e76-acef-9a821301ed74","outputId":"c64dc954-e0a2-4380-a458-01bf0af461ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Nov 11 19:20:22 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.216.01             Driver Version: 535.216.01   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n","| N/A   49C    P0              82W / 300W |  81047MiB / 81920MiB |     35%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n","| N/A   37C    P0              76W / 300W |   1823MiB / 81920MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|    0   N/A  N/A      2799      G   /usr/lib/xorg/Xorg                            4MiB |\n","|    0   N/A  N/A   1140297      C   python                                     6332MiB |\n","|    0   N/A  N/A   2994667      C   /usr/bin/python3                          73354MiB |\n","|    0   N/A  N/A   3548304      C   python                                     1328MiB |\n","|    1   N/A  N/A      2799      G   /usr/lib/xorg/Xorg                            4MiB |\n","|    1   N/A  N/A   2085624      C   /usr/bin/python3                            794MiB |\n","|    1   N/A  N/A   2994667      C   /usr/bin/python3                            582MiB |\n","|    1   N/A  N/A   3548304      C   python                                      414MiB |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"1ad2472b-94c3-4ff3-bb8e-bb2ff1559f3d","metadata":{"id":"1ad2472b-94c3-4ff3-bb8e-bb2ff1559f3d"},"outputs":[],"source":["import tensorflow as tf\n","gpus = tf.config.list_physical_devices('GPU')\n","if len(gpus) > 0:\n","    # Set memory growth to avoid memory issues\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4a3c8e35-637d-4d15-828e-8bc2c317faa4","metadata":{"id":"4a3c8e35-637d-4d15-828e-8bc2c317faa4","outputId":"a68d6bf7-703a-4aa8-826b-049b35c310bd"},"outputs":[{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["gpus"]},{"cell_type":"code","execution_count":null,"id":"449ab0c7-c566-466b-acff-9a24c9f631ee","metadata":{"id":"449ab0c7-c566-466b-acff-9a24c9f631ee","outputId":"47ecd0fb-8c9f-48a7-bc25-ec60ab1a6b40"},"outputs":[{"name":"stdout","output_type":"stream","text":["   profile_id      CE     CP    EPS1   FS1     FS2     PS1     PS2    PS3  \\\n","0           1  47.202  2.184  2411.6  8.99  10.179  151.47  125.50  2.305   \n","1           1  47.202  2.184  2411.6  8.99  10.179  151.45  125.39  2.305   \n","2           1  47.202  2.184  2411.6  8.99  10.179  151.52  125.40  2.336   \n","3           1  47.202  2.184  2411.6  8.99  10.179  151.27  125.03  2.578   \n","4           1  47.202  2.184  2411.6  8.99  10.179  150.80  124.05  2.977   \n","\n","   PS4  ...    TS1     TS2    TS3     TS4    VS1  cooler  valve  leakage  \\\n","0  0.0  ...  35.57  40.961  38.32  30.363  0.604       3    100        0   \n","1  0.0  ...  35.57  40.961  38.32  30.363  0.604       3    100        0   \n","2  0.0  ...  35.57  40.961  38.32  30.363  0.604       3    100        0   \n","3  0.0  ...  35.57  40.961  38.32  30.363  0.604       3    100        0   \n","4  0.0  ...  35.57  40.961  38.32  30.363  0.604       3    100        0   \n","\n","   accumulator  stable  \n","0          130       1  \n","1          130       1  \n","2          130       1  \n","3          130       1  \n","4          130       1  \n","\n","[5 rows x 23 columns]\n","Features shape: (13230000, 18), Target shape: (13230000, 2)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import gc\n","import os\n","from typing import List, Dict, Iterable\n","\n","# --- Constants ---\n","PATH_TO_DATA = \"./Hydraulics/\"\n","NUMBER_OF_PROFILES = 2205\n","PROFILE_MAX_SAMPLE_RATE = 6000\n","TARGET_NAMES = [\"cooler\", \"valve\", \"leakage\", \"accumulator\", \"stable\"]\n","\n","# --- Sensor Files Configuration ---\n","sensor_files_config = [\n","    {\"name\": \"CE\", \"upsample_coeff\": 100},\n","    {\"name\": \"CP\", \"upsample_coeff\": 100},\n","    {\"name\": \"EPS1\", \"upsample_coeff\": 1},\n","    {\"name\": \"FS1\", \"upsample_coeff\": 10},\n","    {\"name\": \"FS2\", \"upsample_coeff\": 10},\n","    {\"name\": \"PS1\", \"upsample_coeff\": 1},\n","    {\"name\": \"PS2\", \"upsample_coeff\": 1},\n","    {\"name\": \"PS3\", \"upsample_coeff\": 1},\n","    {\"name\": \"PS4\", \"upsample_coeff\": 1},\n","    {\"name\": \"PS5\", \"upsample_coeff\": 1},\n","    {\"name\": \"PS6\", \"upsample_coeff\": 1},\n","    {\"name\": \"SE\", \"upsample_coeff\": 100},\n","    {\"name\": \"TS1\", \"upsample_coeff\": 100},\n","    {\"name\": \"TS2\", \"upsample_coeff\": 100},\n","    {\"name\": \"TS3\", \"upsample_coeff\": 100},\n","    {\"name\": \"TS4\", \"upsample_coeff\": 100},\n","    {\"name\": \"VS1\", \"upsample_coeff\": 100},\n","]\n","\n","# --- Data Loading Functions ---\n","def get_files_with_resample(config: List[Dict]) -> Iterable[np.ndarray]:\n","    \"\"\"\n","    Load sensor data files, resample based on the configuration, and return the data as a generator.\n","    \"\"\"\n","    for file in config:\n","        try:\n","            file_path = os.path.join(PATH_TO_DATA, file[\"name\"] + \".txt\")\n","            data = np.genfromtxt(file_path, dtype=float, delimiter='\\t')\n","            # Resample data if necessary\n","            yield np.repeat(data, file[\"upsample_coeff\"], axis=1).flatten()\n","        except Exception as e:\n","            print(f\"Error loading file {file['name']}: {e}\")\n","\n","def load_feature_dataframe(config: List[Dict]) -> pd.DataFrame:\n","    \"\"\"\n","    Load feature data into a pandas DataFrame with profile IDs.\n","    \"\"\"\n","    columns = [file[\"name\"] for file in config]\n","    # Convert the generator into a list before stacking\n","    data = np.stack(list(get_files_with_resample(config)), axis=-1)  # Stack all data into a matrix\n","    data_df = pd.DataFrame(data, columns=columns)\n","\n","    profile_ids = np.repeat(range(1, NUMBER_OF_PROFILES + 1), PROFILE_MAX_SAMPLE_RATE)\n","    profile_ids_df = pd.DataFrame(profile_ids, columns=[\"profile_id\"])\n","\n","    return pd.concat([profile_ids_df, data_df], axis=1, sort=False)\n","\n","\n","def load_targets(filename: str) -> pd.DataFrame:\n","    \"\"\"\n","    Load the target conditions (e.g., stable, valve failure) for each profile.\n","    \"\"\"\n","    try:\n","        conditions_data = np.genfromtxt(os.path.join(PATH_TO_DATA, filename), dtype=int, delimiter='\\t')\n","        conditions_df = pd.DataFrame(conditions_data, columns=TARGET_NAMES)\n","\n","        profile_ids = range(1, NUMBER_OF_PROFILES + 1)\n","        profile_ids_df = pd.DataFrame(profile_ids, columns=[\"profile_id\"])\n","\n","        return pd.concat([profile_ids_df, conditions_df], axis=1, sort=False)\n","    except Exception as e:\n","        print(f\"Error loading target file: {e}\")\n","\n","# --- Load Features and Targets ---\n","feature_df = load_feature_dataframe(sensor_files_config)\n","target_df = load_targets(\"profile.txt\")\n","\n","# --- Memory Cleanup ---\n","_ = gc.collect()\n","\n","# --- Merge Features and Targets by 'profile_id' ---\n","merged_df = pd.merge(feature_df, target_df, on=\"profile_id\", how=\"inner\")\n","\n","# --- Handle Missing Values ---\n","merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","merged_df.dropna(axis=0, inplace=True)  # Drop rows with NaN values\n","\n","# --- Show Sample Data ---\n","print(merged_df.head())\n","\n","# --- Example of Data Preprocessing and Feature Selection ---\n","# Extract feature columns (excluding target columns)\n","X = merged_df.drop(columns=TARGET_NAMES)  # Drop all target columns, keep 'profile_id'\n","y = merged_df[[\"profile_id\", \"stable\"]]  # Keep only 'profile_id' and 'stable' as target columns\n","\n","# --- One-hot encode the target 'stable' column ---\n","y = pd.get_dummies(y[\"stable\"], prefix=\"stable\")\n","\n","print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n"]},{"cell_type":"code","execution_count":null,"id":"27609e4e-867e-468d-887a-2d61e0ca1fea","metadata":{"id":"27609e4e-867e-468d-887a-2d61e0ca1fea","outputId":"411062ca-bda4-41cd-8ea5-730ddd2e6adf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set distribution:\n","stable\n","0    6954000\n","1    3630000\n","Name: count, dtype: int64\n","Test set distribution:\n","stable\n","0    1740000\n","1     906000\n","Name: count, dtype: int64\n"]}],"source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Ensure the profile split is stratified based on the stable flag\n","# Get a list of unique profile ids\n","profile_ids = merged_df['profile_id'].unique()\n","\n","# Get the stable flag for each profile\n","profile_stable_flags = merged_df.groupby('profile_id')['stable'].first().values\n","\n","# Perform stratified split based on profile_stable_flags\n","train_profile_ids, test_profile_ids = train_test_split(profile_ids,\n","                                                       test_size=0.2,  # 80% train, 20% test\n","                                                       stratify=profile_stable_flags)\n","\n","# Now filter the main dataset to get the training and testing sets based on the split profile ids\n","train_df = merged_df[merged_df['profile_id'].isin(train_profile_ids)]\n","test_df = merged_df[merged_df['profile_id'].isin(test_profile_ids)]\n","\n","# Check the distribution of 'stable' in train and test sets\n","print(f\"Train set distribution:\\n{train_df['stable'].value_counts()}\")\n","print(f\"Test set distribution:\\n{test_df['stable'].value_counts()}\")\n"]},{"cell_type":"code","execution_count":null,"id":"3ec06423-422c-4fd8-9ba9-bdb9610831a3","metadata":{"id":"3ec06423-422c-4fd8-9ba9-bdb9610831a3"},"outputs":[],"source":["PATH_TO_DATA = \"./Hydraulics/\"\n"]},{"cell_type":"code","execution_count":null,"id":"f249e4d1-006d-4ed3-a5a0-2a44d3d40942","metadata":{"id":"f249e4d1-006d-4ed3-a5a0-2a44d3d40942","outputId":"6c1b6fa0-d8fd-447d-ca54-54433869ec97"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (1764, 6000, 21), Training target shape: (10584000, 2)\n","Testing data shape: (441, 6000, 21), Testing target shape: (2646000, 2)\n"]}],"source":["# --- Preprocessing for transformer model ---\n","# Separate features and targets for training and testing\n","X_train = train_df.drop(columns=[\"profile_id\", \"stable\"])\n","y_train = train_df[[\"profile_id\", \"stable\"]]\n","\n","X_test = test_df.drop(columns=[\"profile_id\", \"stable\"])\n","y_test = test_df[[\"profile_id\", \"stable\"]]\n","\n","# Sequence shaping for transformer model (reshape for temporal data)\n","X_train_seq = X_train.values.reshape(-1, PROFILE_MAX_SAMPLE_RATE, X_train.shape[1])\n","X_test_seq = X_test.values.reshape(-1, PROFILE_MAX_SAMPLE_RATE, X_test.shape[1])\n","\n","# Ensure target y is in the correct format (for binary classification)\n","y_train = pd.get_dummies(y_train['stable'])\n","y_test = pd.get_dummies(y_test['stable'])\n","\n","# --- Confirm final shapes ---\n","print(f\"Training data shape: {X_train_seq.shape}, Training target shape: {y_train.shape}\")\n","print(f\"Testing data shape: {X_test_seq.shape}, Testing target shape: {y_test.shape}\")\n"]},{"cell_type":"code","execution_count":null,"id":"68b78347-705f-4f70-908f-0a0dcdec4c17","metadata":{"id":"68b78347-705f-4f70-908f-0a0dcdec4c17","outputId":"7efd7e95-1b34-44e4-cec0-c38f8f03d3b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-10 16:40:07.157975: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 16:40:07.269835: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-10 16:40:07.299150: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-10 16:40:07.816468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 16:40:07.816541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 16:40:07.816548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2024-11-10 16:40:09.027148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 16:40:10.399064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 72572 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:17:00.0, compute capability: 8.0\n","2024-11-10 16:40:10.400724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78910 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:31:00.0, compute capability: 8.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-11-10 16:40:15.009685: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8905\n","2024-11-10 16:40:15.178143: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"]},{"name":"stdout","output_type":"stream","text":["220/220 [==============================] - 69s 298ms/step - loss: 264997.1577\n","221/220 [==============================] - 71s 305ms/step - loss: 264616.2033\n","Model saved at epoch 1\n","Epoch 2/10\n","220/220 [==============================] - 59s 270ms/step - loss: 52449.1045\n","221/220 [==============================] - 60s 270ms/step - loss: 52222.0708\n","Model saved at epoch 2\n","Epoch 3/10\n","220/220 [==============================] - 59s 269ms/step - loss: 2444.9815\n","221/220 [==============================] - 59s 269ms/step - loss: 2442.1481\n","Model saved at epoch 3\n","Epoch 4/10\n","220/220 [==============================] - 61s 276ms/step - loss: 2491.5810\n","221/220 [==============================] - 61s 276ms/step - loss: 2488.5415\n","Model saved at epoch 4\n","Epoch 5/10\n","220/220 [==============================] - 76s 344ms/step - loss: 2493.5958\n","221/220 [==============================] - 76s 344ms/step - loss: 2490.5553\n","Model saved at epoch 5\n","Epoch 6/10\n","220/220 [==============================] - 72s 327ms/step - loss: 2494.2179\n","221/220 [==============================] - 72s 327ms/step - loss: 2491.1782\n","Model saved at epoch 6\n","Epoch 7/10\n","220/220 [==============================] - 60s 271ms/step - loss: 2494.0162\n","221/220 [==============================] - 60s 271ms/step - loss: 2490.9787\n","Model saved at epoch 7\n","Epoch 8/10\n","220/220 [==============================] - 59s 269ms/step - loss: 2493.1558\n","221/220 [==============================] - 59s 269ms/step - loss: 2490.1199\n","Model saved at epoch 8\n","Epoch 9/10\n","220/220 [==============================] - 59s 268ms/step - loss: 2493.8677\n","221/220 [==============================] - 59s 268ms/step - loss: 2490.8232\n","Model saved at epoch 9\n","Epoch 10/10\n","220/220 [==============================] - 59s 269ms/step - loss: 2488.6634\n","221/220 [==============================] - 59s 269ms/step - loss: 2485.6406\n","Model saved at epoch 10\n","Final model saved successfully!\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","from tensorflow.keras.utils import Progbar\n","import matplotlib.pyplot as plt\n","from sklearn.svm import OneClassSVM\n","\n","# --- Positional Encoding ---\n","def positional_encoding(position, d_model):\n","    angle_rads = tf.range(start=0, limit=position, delta=1, dtype=tf.float32)\n","    angle_rads = angle_rads[:, tf.newaxis]  # Shape: (position, 1)\n","\n","    i = tf.range(d_model, dtype=tf.float32)\n","    i = i[tf.newaxis, :]  # Shape: (1, d_model)\n","\n","    angle_rates = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(d_model, dtype=tf.float32))\n","    angle_rads = angle_rads * angle_rates  # Shape: (position, d_model)\n","\n","    sines = tf.sin(angle_rads[:, 0::2])  # Apply sine to even indices\n","    cosines = tf.cos(angle_rads[:, 1::2])  # Apply cosine to odd indices\n","\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)  # Shape: (position, d_model)\n","\n","    return pos_encoding\n","\n","# --- Transformer Autoencoder Model ---\n","def create_transformer_autoencoder(input_shape, d_model=21):\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Positional Encoding\n","    pos_enc = positional_encoding(input_shape[0], d_model)  # Shape: (seq_len, d_model)\n","    pos_enc = tf.expand_dims(pos_enc, axis=0)  # Add batch dimension, shape: (1, seq_len, d_model)\n","    pos_enc = tf.tile(pos_enc, [tf.shape(inputs)[0], 1, 1])  # Tile to match batch size, shape: (batch_size, seq_len, d_model)\n","\n","    inputs_with_pos = inputs + pos_enc\n","\n","    # Encoder\n","    x = layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(inputs_with_pos)  # Conv1D\n","    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # Multi-Head Attention\n","    x = layers.LayerNormalization()(x)\n","    x = layers.Dropout(0.1)(x)\n","\n","    # Match the channels of inputs_with_pos to x before residual connection\n","    inputs_with_pos_resized = layers.Conv1D(filters=32, kernel_size=1, padding='same')(inputs_with_pos)\n","\n","    # Residual connection with matching channels\n","    x = layers.add([x, inputs_with_pos_resized])  # Residual connection\n","    x = layers.GlobalAveragePooling1D()(x)\n","\n","    # Decoder\n","    x = layers.RepeatVector(input_shape[0])(x)\n","    x = layers.LSTM(128, return_sequences=True)(x)  # LSTM\n","    x = layers.TimeDistributed(layers.Dense(64, activation='relu'))(x)  # MLP for reconstruction\n","    x = layers.TimeDistributed(layers.Dense(32, activation='relu'))(x)\n","    decoded = layers.TimeDistributed(layers.Dense(input_shape[1]))(x)\n","\n","    # Model setup\n","    model = models.Model(inputs, decoded)\n","    return model\n","\n","\n","# --- Training and Anomaly Detection ---\n","# (Assuming you have your X_train_seq, X_test_seq, y_train, y_test data loaded)\n","\n","# Create the model\n","input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])  # Adjust shape according to your data\n","model = create_transformer_autoencoder(input_shape)\n","\n","# Compile the model (with a smaller learning rate to help with stability)\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","# --- Memory Efficient Training (with Batch Generator) ---\n","def batch_generator(data, batch_size):\n","    \"\"\"Generates batches of data for training.\"\"\"\n","    num_samples = data.shape[0]\n","    for i in range(0, num_samples, batch_size):\n","        yield data[i:i + batch_size]\n","\n","\n","\n","# --- Training Loop with Progbar ---\n","epochs = 10\n","batch_size = 8\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    progbar = Progbar(target=len(X_train_seq)//batch_size)\n","\n","    for batch_idx, batch_x in enumerate(batch_generator(X_train_seq, batch_size)):\n","        loss = model.train_on_batch(batch_x, batch_x)\n","\n","        # Update progress bar with dynamic loss value\n","        progbar.update(batch_idx + 1, values=[(\"loss\", loss)])\n","\n","    # Save the model after each epoch\n","    model.save('my_model_epoch_{}.h5'.format(epoch+1))\n","    print(f\"Model saved at epoch {epoch+1}\")\n","\n","# --- Save the final model after training ---\n","model.save('final_model.h5')  # Save the final model after all epochs are completed\n","print(\"Final model saved successfully!\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0021be02-5e32-4df4-ac5d-51d6e3649713","metadata":{"id":"0021be02-5e32-4df4-ac5d-51d6e3649713","outputId":"6f8053bb-4ff5-41f1-c173-911fa5cd9d1c"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-10 17:32:59.401587: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 17:32:59.560307: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-10 17:32:59.609144: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-10 17:33:01.189070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 17:33:01.189207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 17:33:01.189222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2024-11-10 17:33:03.215410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 17:33:04.779204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 72572 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:17:00.0, compute capability: 8.0\n","2024-11-10 17:33:04.780813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78910 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:31:00.0, compute capability: 8.0\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully!\n"]}],"source":["import tensorflow as tf\n","model = tf.keras.models.load_model('final_model.h5')\n","print(\"Model loaded successfully!\")"]},{"cell_type":"code","execution_count":null,"id":"f6a37e70-52d1-491a-8996-aab18a7eab8f","metadata":{"id":"f6a37e70-52d1-491a-8996-aab18a7eab8f","outputId":"7ac4c5a7-b559-4c45-e599-3f2162825e8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2 Physical GPUs, 1 Logical GPU(s)\n","Epoch 1/5\n","21/32 [==================>...........] - ETA: 0s - loss: 2.4590 - accuracy: 0.1057Epoch 1 completed. Using /physical_device:GPU:1.\n","32/32 [==============================] - 1s 5ms/step - loss: 2.4289 - accuracy: 0.1100\n","Epoch 2/5\n","31/32 [============================>.] - ETA: 0s - loss: 2.3019 - accuracy: 0.1260Epoch 2 completed. Using /physical_device:GPU:1.\n","32/32 [==============================] - 0s 5ms/step - loss: 2.3014 - accuracy: 0.1260\n","Epoch 3/5\n","32/32 [==============================] - ETA: 0s - loss: 2.2840 - accuracy: 0.1220Epoch 3 completed. Using /physical_device:GPU:1.\n","32/32 [==============================] - 0s 5ms/step - loss: 2.2840 - accuracy: 0.1220\n","Epoch 4/5\n","23/32 [====================>.........] - ETA: 0s - loss: 2.2738 - accuracy: 0.1386Epoch 4 completed. Using /physical_device:GPU:1.\n","32/32 [==============================] - 0s 5ms/step - loss: 2.2732 - accuracy: 0.1370\n","Epoch 5/5\n","23/32 [====================>.........] - ETA: 0s - loss: 2.2312 - accuracy: 0.1671Epoch 5 completed. Using /physical_device:GPU:1.\n","32/32 [==============================] - 0s 5ms/step - loss: 2.2386 - accuracy: 0.1660\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","# Custom callback to print the GPU used after each epoch\n","class PrintGPUUsageCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Get the current device being used\n","        device = tf.config.experimental.list_physical_devices('GPU')[gpu_number]\n","        print(f\"Epoch {epoch + 1} completed. Using {device.name}.\")\n","\n","gpu_number = 1  # Use the second GPU (GPU 1)\n","gpus = tf.config.list_physical_devices('GPU')\n","\n","# Set the second GPU as visible\n","if gpus:\n","    if gpu_number < len(gpus):\n","        tf.config.experimental.set_visible_devices(gpus[gpu_number], 'GPU')\n","        tf.config.experimental.set_memory_growth(gpus[gpu_number], True)\n","\n","        # Verify GPU usage\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPU(s)\")\n","\n","        # Sample model definition\n","        model = tf.keras.Sequential([\n","            tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n","            tf.keras.layers.Dropout(0.2),\n","            tf.keras.layers.Dense(10, activation='softmax')\n","        ])\n","\n","        model.compile(optimizer='adam',\n","                      loss='sparse_categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","        # Create random training data\n","        x_train = np.random.random((1000, 784))\n","        y_train = np.random.randint(0, 10, size=(1000,))\n","\n","        # Train the model using GPU 1\n","        with tf.device('/GPU:1'):\n","            model.fit(x_train, y_train, epochs=5, batch_size=32, callbacks=[PrintGPUUsageCallback()])\n","    else:\n","        print(f\"GPU number {gpu_number} is out of range. Available GPUs are indexed from 0 to {len(gpus)-1}.\")\n","else:\n","    print(\"No GPUs available.\")\n"]},{"cell_type":"code","execution_count":null,"id":"61caa6a6-2552-4215-b53e-a7d914188f7d","metadata":{"id":"61caa6a6-2552-4215-b53e-a7d914188f7d"},"outputs":[],"source":["train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)"]},{"cell_type":"code","execution_count":null,"id":"51940322-a566-4f78-9bd9-91336832587d","metadata":{"id":"51940322-a566-4f78-9bd9-91336832587d"},"outputs":[],"source":["\n","# --- Loading the Model for Prediction ---\n","# After training, you can load the model for prediction later\n","# Uncomment the following lines to load the model (if needed)\n","\n","\n","# --- Anomaly Detection ---\n","train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)\n","\n","# Calculate MSE\n","train_mse = np.mean(np.square(X_train_seq - train_reconstruction), axis=(1, 2))\n","test_mse = np.mean(np.square(X_test_seq - test_reconstruction), axis=(1, 2))\n","\n","# Adaptive Thresholding with One-Class SVM\n","ocsvm = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')\n","ocsvm.fit(train_mse.reshape(-1, 1))\n","\n","# Detect anomalies\n","train_anomalies = ocsvm.predict(train_mse.reshape(-1, 1)) == -1\n","test_anomalies = ocsvm.predict(test_mse.reshape(-1, 1)) == -1\n","\n","# --- Accuracy Calculation ---\n","y_train_stable = y_train[\"stable_0\"].values  # Ensure this column exists in y_train\n","y_test_stable = y_test[\"stable_0\"].values\n","\n","train_anomalies_binary = train_anomalies.astype(int)\n","test_anomalies_binary = test_anomalies.astype(int)\n","\n","train_accuracy = np.mean(train_anomalies_binary == y_train_stable)\n","test_accuracy = np.mean(test_anomalies_binary == y_test_stable)\n","\n","print(f\"Training set accuracy: {train_accuracy:.4f}\")\n","print(f\"Test set accuracy: {test_accuracy:.4f}\")\n","\n","# --- Visualization (Optional) ---\n","plt.plot(train_mse[:100], label=\"Train MSE (first 100 samples)\")\n","plt.axhline(y=ocsvm.decision_function(train_mse.reshape(-1, 1)).mean(), color='r', linestyle='--', label=\"Threshold\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"e6ce321c-603c-44db-9053-f3a6248f6a61","metadata":{"id":"e6ce321c-603c-44db-9053-f3a6248f6a61","outputId":"3fc8d3c0-9997-4a71-8adb-6c8d07080a4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","220/220 [==============================] - 61s 268ms/step - loss: 267096.1899\n","221/220 [==============================] - 63s 275ms/step - loss: 266689.8339\n","Epoch 2/10\n","220/220 [==============================] - 69s 313ms/step - loss: 45973.3078\n","221/220 [==============================] - 69s 313ms/step - loss: 45773.9149\n","Epoch 3/10\n","220/220 [==============================] - 74s 338ms/step - loss: 2444.1794\n","221/220 [==============================] - 75s 338ms/step - loss: 2441.3314\n","Epoch 4/10\n","220/220 [==============================] - 72s 326ms/step - loss: 2472.2302\n","221/220 [==============================] - 72s 326ms/step - loss: 2469.2652\n","Epoch 5/10\n","220/220 [==============================] - 70s 317ms/step - loss: 2473.4020\n","221/220 [==============================] - 70s 317ms/step - loss: 2470.4368\n","Epoch 6/10\n","220/220 [==============================] - 70s 318ms/step - loss: 2473.1307\n","221/220 [==============================] - 70s 318ms/step - loss: 2470.1669\n","Epoch 7/10\n","220/220 [==============================] - 73s 331ms/step - loss: 2472.2013\n","221/220 [==============================] - 73s 331ms/step - loss: 2469.2394\n","Epoch 8/10\n","220/220 [==============================] - 72s 327ms/step - loss: 2469.9456\n","221/220 [==============================] - 72s 327ms/step - loss: 2466.9887\n","Epoch 9/10\n","220/220 [==============================] - 70s 316ms/step - loss: 2468.2493\n","221/220 [==============================] - 70s 316ms/step - loss: 2465.2994\n","Epoch 10/10\n","220/220 [==============================] - 72s 328ms/step - loss: 2466.9902\n","221/220 [==============================] - 73s 328ms/step - loss: 2464.0441\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","from tensorflow.keras.utils import Progbar\n","import matplotlib.pyplot as plt\n","from sklearn.svm import OneClassSVM\n","\n","# --- Positional Encoding ---\n","def positional_encoding(position, d_model):\n","    angle_rads = tf.range(start=0, limit=position, delta=1, dtype=tf.float32)\n","    angle_rads = angle_rads[:, tf.newaxis]  # Shape: (position, 1)\n","\n","    i = tf.range(d_model, dtype=tf.float32)\n","    i = i[tf.newaxis, :]  # Shape: (1, d_model)\n","\n","    angle_rates = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(d_model, dtype=tf.float32))\n","    angle_rads = angle_rads * angle_rates  # Shape: (position, d_model)\n","\n","    sines = tf.sin(angle_rads[:, 0::2])  # Apply sine to even indices\n","    cosines = tf.cos(angle_rads[:, 1::2])  # Apply cosine to odd indices\n","\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)  # Shape: (position, d_model)\n","\n","    return pos_encoding\n","\n","# --- Transformer Autoencoder Model ---\n","# --- Transformer Autoencoder Model ---\n","def create_transformer_autoencoder(input_shape, d_model=21):\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Positional Encoding\n","    pos_enc = positional_encoding(input_shape[0], d_model)  # Shape: (seq_len, d_model)\n","    pos_enc = tf.expand_dims(pos_enc, axis=0)  # Add batch dimension, shape: (1, seq_len, d_model)\n","    pos_enc = tf.tile(pos_enc, [tf.shape(inputs)[0], 1, 1])  # Tile to match batch size, shape: (batch_size, seq_len, d_model)\n","\n","    inputs_with_pos = inputs + pos_enc\n","\n","    # Encoder\n","    x = layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(inputs_with_pos)  # Conv1D\n","    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # Multi-Head Attention\n","    x = layers.LayerNormalization()(x)\n","    x = layers.Dropout(0.1)(x)\n","\n","    # Match the channels of inputs_with_pos to x before residual connection\n","    inputs_with_pos_resized = layers.Conv1D(filters=32, kernel_size=1, padding='same')(inputs_with_pos)\n","\n","    # Residual connection with matching channels\n","    x = layers.add([x, inputs_with_pos_resized])  # Residual connection\n","    x = layers.GlobalAveragePooling1D()(x)\n","\n","    # Decoder\n","    x = layers.RepeatVector(input_shape[0])(x)\n","    x = layers.LSTM(128, return_sequences=True)(x)  # LSTM\n","    x = layers.TimeDistributed(layers.Dense(64, activation='relu'))(x)  # MLP for reconstruction\n","    x = layers.TimeDistributed(layers.Dense(32, activation='relu'))(x)\n","    decoded = layers.TimeDistributed(layers.Dense(input_shape[1]))(x)\n","\n","    # Model setup\n","    model = models.Model(inputs, decoded)\n","    return model\n","\n","\n","\n","# --- Training and Anomaly Detection ---\n","# (Assuming you have your X_train_seq, X_test_seq, y_train, y_test data loaded)\n","\n","# Create the model\n","input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])  # Adjust shape according to your data\n","model = create_transformer_autoencoder(input_shape)\n","\n","# Compile the model (with a smaller learning rate to help with stability)\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","# --- Memory Efficient Training (with Batch Generator) ---\n","def batch_generator(data, batch_size):\n","    \"\"\"Generates batches of data for training.\"\"\"\n","    num_samples = data.shape[0]\n","    for i in range(0, num_samples, batch_size):\n","        yield data[i:i + batch_size]\n","\n","\n","\n","# --- Training Loop with Progbar ---\n","epochs = 10\n","batch_size = 8\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    progbar = Progbar(target=len(X_train_seq)//batch_size)\n","\n","    for batch_idx, batch_x in enumerate(batch_generator(X_train_seq, batch_size)):\n","        loss = model.train_on_batch(batch_x, batch_x)\n","\n","        # Update progress bar with dynamic loss value\n","        progbar.update(batch_idx + 1, values=[(\"loss\", loss)])\n","\n","\n","# --- Anomaly Detection ---\n","train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)\n","\n","# Calculate MSE\n","train_mse = np.mean(np.square(X_train_seq - train_reconstruction), axis=(1, 2))\n","test_mse = np.mean(np.square(X_test_seq - test_reconstruction), axis=(1, 2))\n","\n","# Adaptive Thresholding with One-Class SVM\n","ocsvm = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')\n","ocsvm.fit(train_mse.reshape(-1, 1))\n","\n","# Detect anomalies\n","train_anomalies = ocsvm.predict(train_mse.reshape(-1, 1)) == -1\n","test_anomalies = ocsvm.predict(test_mse.reshape(-1, 1)) == -1\n","\n","# --- Accuracy Calculation ---\n","y_train_stable = y_train[\"stable_0\"].values  # Ensure this column exists in y_train\n","y_test_stable = y_test[\"stable_0\"].values\n","\n","train_anomalies_binary = train_anomalies.astype(int)\n","test_anomalies_binary = test_anomalies.astype(int)\n","\n","train_accuracy = np.mean(train_anomalies_binary == y_train_stable)\n","test_accuracy = np.mean(test_anomalies_binary == y_test_stable)\n","\n","print(f\"Training set accuracy: {train_accuracy:.4f}\")\n","print(f\"Test set accuracy: {test_accuracy:.4f}\")\n","\n","# --- Visualization (Optional) ---\n","plt.plot(train_mse[:100], label=\"Train MSE (first 100 samples)\")\n","plt.axhline(y=ocsvm.decision_function(train_mse.reshape(-1, 1)).mean(), color='r', linestyle='--', label=\"Threshold\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"9fbc8d18-9a7f-4cfe-b147-97f3e80b53d6","metadata":{"id":"9fbc8d18-9a7f-4cfe-b147-97f3e80b53d6"},"outputs":[],"source":["# --- Anomaly Detection ---\n","# After training the model, calculate the reconstruction error on both training and test sets.\n","train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)\n","\n","# Calculate Mean Squared Error (MSE) between input and output (reconstructed data)\n","train_mse = np.mean(np.square(X_train_seq - train_reconstruction), axis=(1, 2))  # MSE per sample\n","test_mse = np.mean(np.square(X_test_seq - test_reconstruction), axis=(1, 2))\n","\n","# Threshold for anomaly detection (can be tuned based on the distribution of MSE values)\n","threshold = np.percentile(train_mse, 95)  # Define a threshold (e.g., 95th percentile of MSE)\n","\n","# Detect anomalies based on the threshold\n","train_anomalies = train_mse > threshold\n","test_anomalies = test_mse > threshold\n","\n","# Print anomaly counts\n","print(f\"Training set anomalies: {np.sum(train_anomalies)}\")\n","print(f\"Test set anomalies: {np.sum(test_anomalies)}\")\n","\n","# --- Accuracy Calculation ---\n","# Assuming that the ground truth for anomalies is given by the \"stable\" flag (0 = stable, 1 = unstable)\n","# We assume stable is \"normal\" and unstable as \"anomaly\"\n","y_train_stable = y_train[\"stable_0\"].values  # If 0 is stable, then `stable_0` column should be 1 for stable\n","y_test_stable = y_test[\"stable_0\"].values\n","\n","# Convert anomaly detection result to binary (0 = no anomaly, 1 = anomaly)\n","train_anomalies_binary = train_anomalies.astype(int)\n","test_anomalies_binary = test_anomalies.astype(int)\n","\n","# Calculate accuracy by comparing predicted anomalies to actual anomalies (stable = 0, anomaly = 1)\n","train_accuracy = np.mean(train_anomalies_binary == y_train_stable)\n","test_accuracy = np.mean(test_anomalies_binary == y_test_stable)\n","\n","print(f\"Training set accuracy: {train_accuracy:.4f}\")\n","print(f\"Test set accuracy: {test_accuracy:.4f}\")\n","\n","# Optionally, you can visualize some of the anomalies\n","plt.plot(train_mse[:100], label=\"Train MSE (first 100 samples)\")\n","plt.axhline(y=threshold, color='r', linestyle='--', label=\"Threshold\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"b2da97c2-521c-430e-800e-0a06fd0c63af","metadata":{"id":"b2da97c2-521c-430e-800e-0a06fd0c63af","outputId":"ca40f0ab-9d63-4f32-9f87-bd7808ebd077"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Anomaly Detection ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# After training the model, calculate the reconstruction error on both training and test sets.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_reconstruction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train_seq)\n\u001b[1;32m      4\u001b[0m test_reconstruction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_seq)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate Mean Squared Error (MSE) between input and output (reconstructed data)\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["\n","# --- Anomaly Detection ---\n","# After training the model, calculate the reconstruction error on both training and test sets.\n","train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)\n","\n","# Calculate Mean Squared Error (MSE) between input and output (reconstructed data)\n","train_mse = np.mean(np.square(X_train_seq - train_reconstruction), axis=(1, 2))  # MSE per sample\n","test_mse = np.mean(np.square(X_test_seq - test_reconstruction), axis=(1, 2))\n","\n","# Threshold for anomaly detection (can be tuned based on the distribution of MSE values)\n","threshold = np.percentile(train_mse, 95)  # Define a threshold (e.g., 95th percentile of MSE)\n","\n","# Detect anomalies based on the threshold\n","train_anomalies = train_mse > threshold\n","test_anomalies = test_mse > threshold\n","\n","# Print anomaly counts\n","print(f\"Training set anomalies: {np.sum(train_anomalies)}\")\n","print(f\"Test set anomalies: {np.sum(test_anomalies)}\")\n","\n","# --- Accuracy Calculation ---\n","# Assuming that the ground truth for anomalies is given by the \"stable\" flag (0 = stable, 1 = unstable)\n","# We assume stable is \"normal\" and unstable as \"anomaly\"\n","y_train_stable = y_train[\"stable_0\"].values  # If 0 is stable, then `stable_0` column should be 1 for stable\n","y_test_stable = y_test[\"stable_0\"].values\n","\n","# Convert anomaly detection result to binary (0 = no anomaly, 1 = anomaly)\n","train_anomalies_binary = train_anomalies.astype(int)\n","test_anomalies_binary = test_anomalies.astype(int)\n","\n","# Calculate accuracy by comparing predicted anomalies to actual anomalies (stable = 0, anomaly = 1)\n","train_accuracy = np.mean(train_anomalies_binary == y_train_stable)\n","test_accuracy = np.mean(test_anomalies_binary == y_test_stable)\n","\n","print(f\"Training set accuracy: {train_accuracy:.4f}\")\n","print(f\"Test set accuracy: {test_accuracy:.4f}\")\n","\n","# Optionally, you can visualize some of the anomalies\n","plt.plot(train_mse[:100], label=\"Train MSE (first 100 samples)\")\n","plt.axhline(y=threshold, color='r', linestyle='--', label=\"Threshold\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"16fd33b3-c4da-4ce4-a0aa-03ca1b0d1153","metadata":{"id":"16fd33b3-c4da-4ce4-a0aa-03ca1b0d1153"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 1. Set up MirroredStrategy for Multi-GPU\n","strategy = tf.distribute.MirroredStrategy()\n","\n","print('Number of devices: ', strategy.num_replicas_in_sync)\n","\n","# 2. Define the model inside the strategy scope\n","with strategy.scope():\n","    # Transformer Autoencoder Model for Anomaly Detection\n","    def create_transformer_autoencoder(input_shape):\n","        inputs = layers.Input(shape=input_shape)\n","\n","        # Encoder\n","        x = layers.MultiHeadAttention(num_heads=8, key_dim=64)(inputs, inputs)\n","        x = layers.LayerNormalization()(x)\n","        x = layers.Dropout(0.1)(x)  # Dropout to reduce overfitting\n","        x = layers.GlobalAveragePooling1D()(x)  # Pooling to reduce dimensionality\n","\n","        # Decoder (Symmetric to Encoder)\n","        x = layers.RepeatVector(input_shape[0])(x)  # Repeat to match the input shape\n","        x = layers.LSTM(128, return_sequences=True)(x)\n","        x = layers.TimeDistributed(layers.Dense(64))(x)\n","        decoded = layers.TimeDistributed(layers.Dense(input_shape[1]))(x)  # Output shape should match input shape\n","\n","        # Model setup\n","        model = models.Model(inputs, decoded)\n","        return model\n","\n","    # 3. Create the Transformer Autoencoder model\n","    input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])  # shape: (timesteps, features)\n","    model = create_transformer_autoencoder(input_shape)\n","\n","    # 4. Compile the model with a reconstruction error loss\n","    model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# 5. Model Summary\n","model.summary()\n","\n","# Check the number of GPUs available\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(f\"Num GPUs Available: {len(physical_devices)}\")\n","\n","# Enable logging of device placement\n","tf.debugging.set_log_device_placement(True)\n","\n","# Set memory growth to avoid out of memory issues\n","if physical_devices:\n","    for gpu in physical_devices:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# 6. Train the model using the MirroredStrategy\n","history = model.fit(\n","    X_train_seq, X_train_seq,\n","    epochs=10,\n","    batch_size=32,  # Batch size for each GPU\n","    validation_data=(X_test_seq, X_test_seq),\n","    verbose=0\n",")\n","\n","# 7. Plotting the loss curves\n","plt.figure(figsize=(10, 6))\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"262552cb-fb54-4c32-b9c9-a3f91969faec","metadata":{"id":"262552cb-fb54-4c32-b9c9-a3f91969faec"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9e394f47-bb72-4295-8af9-672701f9ba8f","metadata":{"id":"9e394f47-bb72-4295-8af9-672701f9ba8f","outputId":"c165d771-ae9a-4e05-996f-58a6efd92394"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n","WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"]},{"name":"stderr","output_type":"stream","text":["2024-11-10 15:35:13.862593: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 15:35:14.843911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78910 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:31:00.0, compute capability: 8.0\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 32)        896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               65664     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 160,202\n","Trainable params: 160,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"ename":"AttributeError","evalue":"module 'tensorflow._api.v2.config' has no attribute 'set_log_device_placement'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpus:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m         \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_log_device_placement\u001b[49m(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m# Limit GPU memory growth\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus:\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.config' has no attribute 'set_log_device_placement'"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Enable mixed precision training (optional for performance)\n","from tensorflow.keras import mixed_precision\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_global_policy(policy)\n","\n","# 1. Use MirroredStrategy for Multi-GPU training\n","strategy = tf.distribute.MirroredStrategy()\n","\n","# 2. Load CIFAR-10 dataset for demonstration\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","# Normalize the data\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# 3. Define a Convolutional Neural Network (CNN) Model\n","def create_cnn_model():\n","    model = models.Sequential([\n","        layers.InputLayer(input_shape=(32, 32, 3)),  # CIFAR-10 images are 32x32x3\n","        layers.Conv2D(32, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(64, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(10, activation='softmax')  # 10 classes for CIFAR-10\n","    ])\n","    return model\n","\n","# 4. Define and compile the model within the strategy scope\n","with strategy.scope():\n","    model = create_cnn_model()\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","# 5. Print the model summary\n","model.summary()\n","\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.set_log_device_placement(True)\n","        # Limit GPU memory growth\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)\n","\n","\n","# 6. Train the model using MirroredStrategy\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=10,\n","    batch_size=16,  # Try reducing the batch size\n","    validation_data=(x_test, y_test),\n","    verbose=2\n",")\n","\n","# 7. Plot training and validation accuracy and loss\n","plt.figure(figsize=(12, 6))\n","\n","# Training accuracy\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='train accuracy')\n","plt.plot(history.history['val_accuracy'], label='val accuracy')\n","plt.title('Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Training loss\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='val loss')\n","plt.title('Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# 8. Evaluate the model on the test set\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"id":"f0a1c92b-4f5b-412a-ada8-de49259a7efc","metadata":{"id":"f0a1c92b-4f5b-412a-ada8-de49259a7efc","outputId":"e12073cc-12a7-4b63-d628-3f4dcc7314ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available: 2\n"]}],"source":["import tensorflow as tf\n","\n","# Check the number of GPUs available\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(f\"Num GPUs Available: {len(physical_devices)}\")\n","\n","# Enable logging of device placement\n","tf.debugging.set_log_device_placement(True)\n","\n","# Set memory growth to avoid out of memory issues\n","if physical_devices:\n","    for gpu in physical_devices:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# Now, you can proceed to train your model\n","# history = model.fit(...)  # Your model fitting code here\n"]},{"cell_type":"code","execution_count":null,"id":"e7a2deda-252e-4463-9d38-c038c299b65d","metadata":{"id":"e7a2deda-252e-4463-9d38-c038c299b65d","outputId":"b1741e63-ccc7-4f1f-8f2d-5a3fa1a68dad"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-10 15:34:06.069917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 15:34:06.222510: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-10 15:34:06.282504: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-10 15:34:07.088237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 15:34:07.088322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2024-11-10 15:34:07.088331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import tensorflow as tf\n","\n","# List available GPUs\n","gpus = tf.config.list_physical_devices('GPU')\n","\n","# Ensure that GPU 1 exists\n","if len(gpus) > 1:\n","    # Set memory growth to avoid OOM errors\n","    tf.config.set_visible_devices(gpus[1], 'GPU')  # Only use GPU 1\n","    tf.config.experimental.set_memory_growth(gpus[1], True)\n","else:\n","    print(\"GPU 1 is not available.\")\n"]},{"cell_type":"code","execution_count":null,"id":"86203355-53e9-46c6-9824-818948ffa99b","metadata":{"id":"86203355-53e9-46c6-9824-818948ffa99b","outputId":"780975ce-26bc-4f7e-f582-c54c8458908b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model loaded successfully!\n"]}],"source":["import tensorflow as tf\n","\n","\n","model = tf.keras.models.load_model('final_model.h5')\n","print(\"Model loaded successfully!\")"]},{"cell_type":"code","execution_count":null,"id":"8dceae3f-910f-4980-9c58-b932bf892e17","metadata":{"id":"8dceae3f-910f-4980-9c58-b932bf892e17","outputId":"120b950f-19cd-4e7b-c2e3-efb8652f6e28"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-11 11:58:42.313053: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n","2024-11-11 11:58:42.313132: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:1134 : UNIMPLEMENTED: DNN library is not found.\n"]},{"ename":"UnimplementedError","evalue":"Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1046, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2994667/917286936.py\", line 1, in <module>\n      train_reconstruction = model.predict(X_train_seq)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDNN library is not found.\n\t [[{{node model/conv1d/Conv1D}}]] [Op:__inference_predict_function_1036483]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_reconstruction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_reconstruction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_seq)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1046, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2994667/917286936.py\", line 1, in <module>\n      train_reconstruction = model.predict(X_train_seq)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDNN library is not found.\n\t [[{{node model/conv1d/Conv1D}}]] [Op:__inference_predict_function_1036483]"]}],"source":["train_reconstruction = model.predict(X_train_seq)\n","test_reconstruction = model.predict(X_test_seq)"]},{"cell_type":"code","execution_count":null,"id":"d7cb5565-f00c-4b85-b46a-4d2250e44d43","metadata":{"id":"d7cb5565-f00c-4b85-b46a-4d2250e44d43","outputId":"21e282b7-60da-467d-be5e-491bbca108a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Available GPUs: 2\n"]},{"ename":"ValueError","evalue":"Cannot set memory growth on device when virtual devices configured","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set memory growth for both GPUs to avoid TensorFlow allocating all memory at once\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Set a memory limit for each GPU (e.g., 10GB per GPU) - for TensorFlow versions < 2.4\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(gpus) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/config.py:716\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_memory_growth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_memory_growth\u001b[39m(device, enable):\n\u001b[1;32m    693\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py:1655\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1652\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized device: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(dev))\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_virtual_device_map:\n\u001b[0;32m-> 1655\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1656\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set memory growth on device when virtual devices configured\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev\u001b[38;5;241m.\u001b[39mdevice_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dev \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pluggable_devices:\n\u001b[1;32m   1659\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set memory growth on non-GPU and non-Pluggable devices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Cannot set memory growth on device when virtual devices configured"]}],"source":["import tensorflow as tf\n","import time\n","\n","# Check available GPUs\n","gpus = tf.config.list_physical_devices('GPU')\n","print(f\"Available GPUs: {len(gpus)}\")\n","\n","if len(gpus) < 2:\n","    raise RuntimeError(\"This script requires at least 2 GPUs. Please check your hardware setup.\")\n","\n","# Set memory growth for both GPUs to avoid TensorFlow allocating all memory at once\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# Set a memory limit for each GPU (e.g., 10GB per GPU) - for TensorFlow versions < 2.4\n","if len(gpus) >= 2:\n","    tf.config.experimental.set_virtual_device_configuration(\n","        gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])  # 10GB for GPU-0\n","    tf.config.experimental.set_virtual_device_configuration(\n","        gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])  # 10GB for GPU-1\n","\n","# Define a function to perform a heavy operation on a given GPU\n","def stress_test_gpu(device, size=1000):  # Reduced tensor size for safety\n","    with tf.device(device):\n","        print(f\"Starting stress test on {device}...\")\n","\n","        # Create large random tensors\n","        A = tf.random.normal([size, size])\n","        B = tf.random.normal([size, size])\n","\n","        # Perform a matrix multiplication operation repeatedly to stress the GPU\n","        start_time = time.time()\n","        for _ in range(40):  # Repeat 10 times\n","            C = tf.matmul(A, B)  # Matrix multiplication\n","            tf.reduce_sum(C)  # To ensure the result is actually computed\n","        end_time = time.time()\n","\n","        print(f\"Stress test on {device} complete in {end_time - start_time:.2f} seconds.\")\n","\n","# Run the stress tests sequentially (one GPU at a time)\n","def run_stress_tests():\n","    # First, stress GPU-0\n","    stress_test_gpu('/GPU:0', size=1000)  # Adjust tensor size to fit in memory\n","\n","    # Then, stress GPU-1\n","    stress_test_gpu('/GPU:1', size=1000)  # Adjust tensor size to fit in memory\n","\n","if __name__ == \"__main__\":\n","    run_stress_tests()\n"]},{"cell_type":"code","execution_count":null,"id":"7121ff80-1bc2-46fd-8eb6-a6c26a6c364b","metadata":{"id":"7121ff80-1bc2-46fd-8eb6-a6c26a6c364b","outputId":"3d8a025e-c2d6-4c39-c190-10559fe60be8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Available kernels:\n","  my_kernel        /home/samarth7022/.local/share/jupyter/kernels/my_kernel\n","  mobilevit        /usr/local/share/jupyter/kernels/mobilevit\n","  myenv            /usr/local/share/jupyter/kernels/myenv\n","  python3          /usr/local/share/jupyter/kernels/python3\n","  python3.10       /usr/local/share/jupyter/kernels/python3.10\n","  tenenv           /usr/local/share/jupyter/kernels/tenenv\n","  tensorflow2_5    /usr/local/share/jupyter/kernels/tensorflow2_5\n","  unet             /usr/local/share/jupyter/kernels/unet\n"]}],"source":["# List all available kernels\n","!jupyter kernelspec list\n"]}],"metadata":{"kernelspec":{"display_name":"tensorflow2_5","language":"python","name":"tensorflow2_5"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}